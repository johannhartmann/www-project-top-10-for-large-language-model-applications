## Brief der Projektleitung

Die OWASP Top 10 für Anwendungen mit Large Language Models (LLMs) wurde 2023 als gemeinschaftsgetriebenes Projekt ins Leben gerufen, um Sicherheitsprobleme speziell für KI-Anwendungen hervorzuheben und anzugehen. Seitdem hat sich die Technologie über verschiedene Branchen und Anwendungen hinweg verbreitet – ebenso wie die damit verbundenen Risiken. Da LLMs zunehmend in allem, von Kundeninteraktionen bis hin zu internen Abläufen, integriert werden, entdecken Entwickler und Sicherheitsfachleute neue Schwachstellen – und Wege, sie zu beheben.

Die Liste von 2023 war ein großer Erfolg, um das Bewusstsein zu schärfen und eine Grundlage für die sichere Nutzung von LLMs zu schaffen. Seitdem haben wir jedoch noch mehr dazugelernt. In dieser neuen Version von 2025 haben wir mit einer größeren, vielfältigeren Gruppe von Mitwirkenden weltweit zusammengearbeitet, die alle dazu beigetragen haben, diese Liste zu gestalten. Der Prozess umfasste Brainstorming-Sitzungen, Abstimmungen und Rückmeldungen aus der Praxis von Fachleuten, die direkt mit der Sicherheit von LLM-Anwendungen befasst sind. Jede Stimme war entscheidend, um diese neue Version so umfassend und praxisnah wie möglich zu gestalten.

### Was ist neu in den Top 10 von 2025?

Die Liste von 2025 spiegelt ein besseres Verständnis der bestehenden Risiken wider und enthält wichtige Aktualisierungen darüber, wie LLMs heute in der Praxis eingesetzt werden. Zum Beispiel erweitert **Unkontrollierter Verbrauch** das bisherige Thema Denial-of-Service, um Risiken im Zusammenhang mit Ressourcenmanagement und unerwarteten Kosten zu berücksichtigen – ein dringendes Problem bei groß angelegten LLM-Bereitstellungen.

Der Eintrag **Vektoren und Embeddings** reagiert auf die Forderungen der Community nach Anleitungen zur Sicherung von Retrieval-Augmented Generation (RAG) und anderen auf Embeddings basierenden Methoden, die mittlerweile zentrale Praktiken für die Verankerung von Modellausgaben darstellen.

Wir haben auch **System-Prompt-Leakage** hinzugefügt, um ein Thema zu behandeln, das reale Exploits umfasst und von der Community stark nachgefragt wurde. Viele Anwendungen gingen davon aus, dass Prompts sicher isoliert seien, aber aktuelle Vorfälle haben gezeigt, dass Entwickler nicht davon ausgehen können, dass Informationen in diesen Prompts vertraulich bleiben.

**Exzessive Agency** wurde erweitert, angesichts der zunehmenden Nutzung von agentischen Architekturen, die dem LLM mehr Autonomie geben. Mit LLMs, die als Agenten oder in Plug-in-Umgebungen agieren, können unkontrollierte Berechtigungen zu unbeabsichtigten oder riskanten Aktionen führen, wodurch dieser Punkt wichtiger denn je wird.

### Ausblick

Wie die Technologie selbst ist auch diese Liste ein Produkt der Einsichten und Erfahrungen der Open-Source-Community. Sie wurde durch Beiträge von Entwicklern, Datenwissenschaftlern und Sicherheitsexperten aus verschiedenen Sektoren geformt, die alle das Ziel teilen, sicherere KI-Anwendungen zu schaffen. Wir sind stolz darauf, Ihnen diese Version von 2025 präsentieren zu können, und hoffen, dass sie Ihnen die Werkzeuge und das Wissen bietet, um LLMs effektiv abzusichern.

Vielen Dank an alle, die geholfen haben, dies zu verwirklichen, und an diejenigen, die weiterhin daran arbeiten, es zu nutzen und zu verbessern. Wir sind dankbar, Teil dieser Arbeit mit Ihnen zu sein.

###@ Steve Wilson
Projektleiter  
OWASP Top 10 für Anwendungen mit Large Language Models  
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technischer Leiter & Verantwortlicher für Schwachstelleneinträge  
OWASP Top 10 für Anwendungen mit Large Language Models  
LinkedIn: https://www.linkedin.com/in/adamdawson0/

